# It is currently under preparation.

# AAAI2023-An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-sourcing

## Overview
This repository contains the codes for the experiments performed in the following papers:
  
Yuya Hikima, Yasunori Akagi, Hideaki Kim, Taichi Asami. "An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-sourcing." In AAAI, 2023 (in press).
  
Contents of this repository:
- **README** This file.
- **SOFTWARE LICENSE AGREEMENT FOR EVALUATION** The user must comply with the rules described herein.
- **Crowd-sourcing_experiment folder** It contains the code used in the crowd-sourcing platform experiment and the code needed to set up the experiment, including data downloads.
- **Details_of_experiments.pdf** It contains detailed information on our experiments.
- **Proof_of_Lemma2.pdf** It contains the proof of Lemma 2 of our paper, which is not included in the paper.

The data for crowd-sourcing experiments are downloaded from
  
http://dbgroup.cs.tsinghua.edu.cn/ligl/crowddata/ (Relevance Finding dataset).
  
The data are shared by
  
Chris Buckley, Matthew Lease, and Mark D. Smucker. "Overview of the TREC 2010 Relevance Feedback Track (Notebook)." In TREC, 2010.

## Description

The following is a description of what is in each folder.
- **Crowd-sourcing_experiment** 
  - **setup.sh** Script for setting up the experiments
  - **Experiment_paper.sh** Scripts for performing the same experiments as in our paper
  - **Experiment_test.sh** Scripts for small experiments to see if the code works
  - **bin** Folder containing the python code needed for the crowd-sourcing experiments
    - **data_download.py** It is executed by setup.sh to download the real data.
    - **generate_reward_matrix.py** It is executed by setup.sh to make simulation data from the real data.
    - **experiment_crowdsourcing_gurobi.py** It is executed by Experiment.sh or Experiment_test.sh to perform experiments using simulated data. The first argument is $m$ (number of tasks), the second is $n$ (number of users), the third is $T$ (number of user appearance), the fourth is the execution time of Bayesian optimization (in seconds), the fifth is the execution time of random search (in seconds), and the sixth is the number of simulations.
    - **experiment_crowdsourcing_cbc.py** Experimental code to replace the above if you do not have a Gurobi license
  - **data** Folder where the downloaded data is stored
  - **work** Folder where the simulation data is stored
    - **Reward_matrix** Data containing w_et in the paper, generated by experiment_crowdsourcing_gurobi.py.
    - **trec-rf10-data.csv** Converted csv data grom the downloaded data
  - **results** Folder where the results are stored
    - **result_m=XX_n=XX_T=XX_BOruntime=XX_RSruntime=XX_simulations=XX.csv** The data containig results for a given parameter set

## Requirement
Codes were implemented in Python 3.6.8.

## Usage
For each experiment, we explain how to perform it.

**Crowd-sourcing experiments** 
1. Go to the Crowd-sourcing_experiment folder, make "results", "data" and "work" folder, and then, run "setup.sh."
1. Run "Experiment_test.sh" and see the results in the "results" folder to see if the code works.
1. Run "Experiment_paper.sh" and see the results in the "results." Note that this code takes a long time to execute and is not parallelized.
  
If you want to set parameters yourself, go to the Crowd-sourcing_experiment/bin folder and run "experiment_crowdsourcing_gurobi.py m n T BO_runtime RS_runtime num_simulations."
The first argument is $m$ (number of tasks), the second is $n$ (number of users), the third is $T$ (number of user appearance), the fourth is the execution time limit of Bayesian optimization (in seconds), the fifth is the execution time limit of random search (in seconds), and the sixth is the number of simulations.

## Licence
You must follow the terms of the "SOFTWARE LICENSE AGREEMENT FOR EVALUATION."
Be sure to read it.

## Author
Yuya Hikima wrote this text.
If you have any problems, please contact yuya.hikima at gmail.com.
