# It is currently under preparation.

# AAAI2023-An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-sourcing

## Overview
This repository contains the codes for the experiments performed in the following papers:
  
Yuya Hikima, Yasunori Akagi, Hideaki Kim, Taichi Asami. "An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-sourcing." In AAAI, 2023 (in press).
  
Contents of this repository:
- **README** This file.
- **SOFTWARE LICENSE AGREEMENT FOR EVALUATION** The user must comply with the rules described herein.
- **Crowd-sourcing_experiment folder** It contains the code used in the crowd-sourcing platform experiment and the code needed to set up the experiment, including data downloads.
- **Appendix.pdf** It contains explanations of related work of online matching and the proof of Lemma 1.

The data for crowd-sourcing experiments are downloaded from
  
http://dbgroup.cs.tsinghua.edu.cn/ligl/crowddata/ (Relevance Finding dataset).
  
The data are shared by
  
Chris Buckley, Matthew Lease, and Mark D. Smucker. "Overview of the TREC 2010 Relevance Feedback Track (Notebook)." In TREC, 2010.

## Description

The following is a description of what is in each folder.
- **Crowd-sourcing_experiment** 
  - **setup.sh** Script for setting up the experiments
  - **run_experiments.sh** Scripts for performing the same simulation experiments with real data as in our paper
  - **run_synthetic_experiments.sh** Scripts for performing the same synthetic experiments as in our paper
  - **bin** Folder containing the python code needed for the crowd-sourcing experiments
    - **data_download.py** It is executed by setup.sh to download the real data.
    - **generate_reward_matrix_from_data.py** It is executed by setup.sh to make simulation data from the real data.
    - **experiments.py** It is executed by run_experiments.sh to perform simulation experiments with real data. The first argument is $m$ (number of tasks), the second is $n$ (number of users), the third is $T$ (number of user appearance), the fourth is the lower bound of b_u (task budgets), the fifth is the upper bound of b_u, the sixth is the execution time of Bayesian optimization (in seconds), the seventh is the execution time of random search (in seconds), and the eighth is the number of simulations.
    - **experiments_synthetic.py** It is executed by run_experiments.sh to perform simulation experiments with real data. The arguments are same as the ``experiments.py''.
  - **data** Folder where the downloaded data is stored
  - **work** Folder where the simulation data is stored
    - **Reward_matrix** Data containing w_et in the paper, generated by generate_reward_matrix_from_data.py.
    - **trec-rf10-data.csv** Converted csv data grom the downloaded data
  - **results** Folder where the results are stored

## Requirement
Codes were implemented in Python 3.6.8.

## Usage
For each experiment, we explain how to perform it.

**Crowd-sourcing experiments** 
1. Go to the Crowd-sourcing_experiment folder, make "results", "data" and "work" folder, and then, run "setup.sh."
1. Run "run_experiments.sh" and see the results in the "results." Note that this code takes a long time to execute.
  
If you want to set parameters yourself, go to the Crowd-sourcing_experiment/bin folder and run "experiment_crowdsourcing_gurobi.py m n T b_u_lower_bound b_u_upper_bound BO_runtime RS_runtime num_simulations."
The first argument is $m$ (number of tasks), the second is $n$ (number of users), the third is $T$ (number of user appearance), the fourth is the lower bound of b_u (task budgets), the fifth is the upper bound of b_u, the sixth is the execution time limit of Bayesian optimization (in seconds), the seventh is the execution time limit of random search (in seconds), and the eighth is the number of simulations.

## Licence
You must follow the terms of the "SOFTWARE LICENSE AGREEMENT FOR EVALUATION."
Be sure to read it.

## Author
Yuya Hikima wrote this text.
If you have any problems, please contact yuya.hikima at gmail.com.
